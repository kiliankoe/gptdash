# GPTDash Environment Configuration

# =============================================================================
# OpenAI Configuration (optional - one of OpenAI or Ollama is needed for AI)
# =============================================================================

# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI model to use (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini

# =============================================================================
# Ollama Configuration (optional - for local LLM)
# =============================================================================

# Requires Ollama running locally: https://ollama.ai
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use (default: llama3.2)
OLLAMA_MODEL=llama3.2

# =============================================================================
# LLM Request Settings
# =============================================================================

# Request timeout in seconds (default: 30)
LLM_TIMEOUT=30

# Maximum tokens for AI responses (default: 150)
LLM_MAX_TOKENS=150

# =============================================================================
# Host Panel Authentication (required for production!)
# =============================================================================

# Both must be set to enable authentication
# If not set, the host panel will be unprotected (warning logged)
HOST_USERNAME=admin
HOST_PASSWORD=your-secure-password-here

# =============================================================================
# Anti-Abuse Protection
# =============================================================================

# Block suspicious user agents like curl, wget, bots (default: true)
ABUSE_BLOCK_USER_AGENTS=true

# Require browser-like headers for WebSocket connections (default: true)
ABUSE_REQUIRE_BROWSER=true

# Enable rate limiting per token (default: true)
ABUSE_RATE_LIMIT=true

# Maximum requests per rate limit window (default: 100)
ABUSE_RATE_LIMIT_MAX=100

# Rate limit window duration in seconds (default: 10)
ABUSE_RATE_LIMIT_WINDOW=10

# =============================================================================
# Logging
# =============================================================================

# Tracing log level (default: gptdash=debug,tower_http=debug,axum=trace)
# Examples: info, debug, gptdash=info, gptdash=debug,tower_http=info
RUST_LOG=gptdash=debug,tower_http=debug

# =============================================================================
# Notes
# =============================================================================

# - You can use either OpenAI, Ollama, or both simultaneously
# - The server will start without LLM providers if none are configured,
#   but AI answer generation will not be available
# - The server listens on port 6573 (hardcoded, ASCII for "AI")
