# GPTDash Environment Configuration

# =============================================================================
# Server Configuration
# =============================================================================

# Server bind address (default: 0.0.0.0)
BIND_ADDR=0.0.0.0

# Server port (default: 6573, ASCII for "AI")
PORT=6573

# Domain for deployment (used by Caddy)
DOMAIN=localhost

# =============================================================================
# Host Panel Authentication (required for production!)
# =============================================================================

# Both must be set to enable authentication
# If not set, the host panel will be unprotected (warning logged)
HOST_USERNAME=admin
HOST_PASSWORD=your-secure-password-here

# =============================================================================
# OpenAI Configuration (optional - one of OpenAI or Ollama is needed for AI)
# =============================================================================

# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI model to use (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini

# =============================================================================
# Ollama Configuration (optional - for local LLM)
# =============================================================================

# Requires Ollama running locally: https://ollama.ai
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use (default: llama3.2)
OLLAMA_MODEL=llama3.2

# =============================================================================
# LLM Request Settings
# =============================================================================

# Request timeout in seconds (default: 30)
LLM_TIMEOUT=30

# Maximum tokens for AI responses (default: 150)
LLM_MAX_TOKENS=150

# =============================================================================
# State Persistence
# =============================================================================

# Auto-save file path (default: ./state_backup.json)
AUTO_SAVE_PATH=./state_backup.json

# Auto-save interval in seconds (default: 5)
AUTO_SAVE_INTERVAL_SECS=5

# Set to 1 to disable auto-save (useful for testing)
# DISABLE_AUTO_SAVE=1

# =============================================================================
# Venue-Only Mode
# =============================================================================

# Comma-separated CIDR ranges for venue-only mode
# When set and enabled, only audience from these IP ranges can join
# Examples: 185.1.74.0/24,2001:db8::/32
# VENUE_IP_RANGES=

# =============================================================================
# Anti-Abuse Protection
# =============================================================================

# Block suspicious user agents like curl, wget, bots (default: true)
ABUSE_BLOCK_USER_AGENTS=true

# Require browser-like headers for WebSocket connections (default: true)
ABUSE_REQUIRE_BROWSER=true

# Enable rate limiting per token (default: true)
ABUSE_RATE_LIMIT=true

# Maximum requests per rate limit window (default: 100)
ABUSE_RATE_LIMIT_MAX=100

# Rate limit window duration in seconds (default: 10)
ABUSE_RATE_LIMIT_WINDOW=10

# =============================================================================
# Testing / Development
# =============================================================================

# Set to 1 to disable vote anti-automation checks (for E2E testing)
# SKIP_VOTE_ANTI_AUTOMATION=1

# =============================================================================
# Logging
# =============================================================================

# Tracing log level (default: gptdash=debug,tower_http=debug,axum=trace)
# Examples: info, debug, gptdash=info, gptdash=debug,tower_http=info
RUST_LOG=gptdash=debug,tower_http=debug

# =============================================================================
# Notes
# =============================================================================

# - You can use either OpenAI, Ollama, or both simultaneously
# - The server will start without LLM providers if none are configured,
#   but AI answer generation will not be available
